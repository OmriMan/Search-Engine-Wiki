{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2y0foj5WC+uj7ZoFTNDfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmriMan/Search-Engine-Wiki/blob/master/PageViewsProcces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QtztUAUPEOyE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import bz2\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from itertools import islice\n",
        "from xml.etree import ElementTree\n",
        "import codecs\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data about page views on Wikipedia is available at https://dumps.wikimedia.org and there is documentation about the definition of a page view and the format of lines in the file. In this project, we will use page view data that the course staff provide for ALL of English Wikipedia from the month of August 2021, which is more than 10.7 million viewed articles. The code below shows how we generate that data."
      ],
      "metadata": {
        "id": "JdQg2cMzHIX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "In the following code we are:\n",
        "* Download the file pageviews-202108-user.bz2 (This file holds information about Wikipedia pages and views of those pages until August 2021) after \"cleaning and\" stem)\n",
        "* Filter noise and leave only page ID and monthly number of views per page ID\n",
        "Filters values ​​that are not numbers or a sequence of numbers\n",
        "* Keep everything as a dictionary (counter) that has been summarized for each ID page, the number of views\n",
        "Then we will have a page map mapping for multiple page views.\n",
        "* Save this dictionary (counter) to a binary file\n",
        "( write out the counter as binary file (pickle it) )\n",
        "*****\n",
        "It makes sense that this code would take some time to run, about 10-15 minutes for home internet infrastructure in an average student apartment in the D neighborhood in Be'er Sheva\n",
        "*****"
      ],
      "metadata": {
        "id": "xzpEgzdJH6lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "# Using user page views (as opposed to spiders and automated traffic) for the \n",
        "# month of August 2021\n",
        "pv_path = 'https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2'\n",
        "p = Path(pv_path) \n",
        "pv_name = p.name\n",
        "pv_temp = f'{p.stem}-4dedup.txt'\n",
        "pv_clean = f'{p.stem}.pkl'\n",
        "# Download the file (2.3GB) \n",
        "!wget -N $pv_path\n",
        "# Filter for English pages, and keep just two fields: article ID (3) and monthly \n",
        "# total number of page views (5). Then, remove lines with article id or page \n",
        "# view values that are not a sequence of digits.\n",
        "!bzcat $pv_name | grep \"^en\\.wikipedia\" | cut -d' ' -f3,5 | grep -P \"^\\d+\\s\\d+$\" > $pv_temp\n",
        "# Create a Counter (dictionary) that sums up the pages views for the same \n",
        "# article, resulting in a mapping from article id to total page views.\n",
        "wid2pv = Counter()\n",
        "with open(pv_temp, 'rt') as f:\n",
        "  for line in f:\n",
        "    parts = line.split(' ')\n",
        "    wid2pv.update({int(parts[0]): int(parts[1])})\n",
        "# write out the counter as binary file (pickle it)\n",
        "with open(pv_clean, 'wb') as f:\n",
        "  pickle.dump(wid2pv, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeDMtT2nHrsg",
        "outputId": "3e5bf1d7-05cd-40a6-8a19-fc6113fe0fa8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-03 13:46:49--  https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2503235912 (2.3G) [application/octet-stream]\n",
            "Saving to: ‘pageviews-202108-user.bz2’\n",
            "\n",
            "pageviews-202108-us 100%[===================>]   2.33G  4.62MB/s    in 8m 42s  \n",
            "\n",
            "2022-01-03 13:55:32 (4.57 MB/s) - ‘pageviews-202108-user.bz2’ saved [2503235912/2503235912]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is an example of how to read the dictionary (counter) we kept in the code above"
      ],
      "metadata": {
        "id": "k_aYUOgcH5U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the counter\n",
        "with open(pv_clean, 'rb') as f:\n",
        "  wid2pv = pickle.loads(f.read())"
      ],
      "metadata": {
        "id": "FBe79jpaL4WW"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}